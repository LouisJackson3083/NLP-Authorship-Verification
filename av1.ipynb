{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/LouisJackson3083/NLP-Authorship-Verification.git\n",
        "%cd NLP-Authorship-Verification/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIsMS4tf04-2",
        "outputId": "08c9cd9f-d31c-451d-b0ed-5a91fbba4046"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'NLP-Authorship-Verification'...\n",
            "remote: Enumerating objects: 313, done.\u001b[K\n",
            "remote: Counting objects: 100% (313/313), done.\u001b[K\n",
            "remote: Compressing objects: 100% (182/182), done.\u001b[K\n",
            "remote: Total 313 (delta 161), reused 262 (delta 110), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (313/313), 19.20 MiB | 20.48 MiB/s, done.\n",
            "Resolving deltas: 100% (161/161), done.\n",
            "/content/NLP-Authorship-Verification\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "j0RWoT-7hV29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "print(f\"Is CUDA supported by this system? {torch.cuda.is_available()}\")\n",
        "print(f\"CUDA version: {torch.version.cuda}\")\n",
        "\n",
        "# Storing ID of current CUDA device\n",
        "cuda_id = torch.cuda.current_device()\n",
        "print(f\"ID of current CUDA device: {torch.cuda.current_device()}\")\n",
        "\n",
        "print(f\"Name of current CUDA device: {torch.cuda.get_device_name(cuda_id)}\")"
      ],
      "metadata": {
        "id": "OGmrDIBFhv9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Makes sure nltk libraries are downloaded\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "id": "JUFFFIhdo-xU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %run ./src/train.py --lr 0.0001 --batch_size 1 --num_workers 1 --dropout 0.5 --num_epochs 100 --ratio 0.01 --patience 15\n",
        "%run ./src/inference.py"
      ],
      "metadata": {
        "id": "df3w99OWh6os"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}